from transformers import MarianMTModel, MarianTokenizer
import gradio as gr

# –ü–æ–¥–¥—ä—Ä–∂–∞–Ω–∏ –µ–∑–∏–∫–æ–≤–∏ –¥–≤–æ–π–∫–∏ –∏ –º–æ–¥–µ–ª–∏
language_pairs = {
    ("bg", "en"): "Helsinki-NLP/opus-mt-bg-en",
    ("en", "bg"): "Helsinki-NLP/opus-mt-en-bg",
    ("en", "ru"): "Helsinki-NLP/opus-mt-en-ru",
    ("ru", "en"): "Helsinki-NLP/opus-mt-ru-en",
    ("en", "zh"): "Helsinki-NLP/opus-mt-en-zh",
    ("zh", "en"): "Helsinki-NLP/opus-mt-zh-en"
}

# –ï–∑–∏—Ü–∏, –≤–∏–¥–∏–º–∏ –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ ‚Üí –µ–∑–∏–∫–æ–≤–∏ –∫–æ–¥–æ–≤–µ
lang_options = {
    "–ë—ä–ª–≥–∞—Ä—Å–∫–∏": "bg",
    "–ê–Ω–≥–ª–∏–π—Å–∫–∏": "en",
    "–†—É—Å–∫–∏": "ru",
    "–ö–∏—Ç–∞–π—Å–∫–∏": "zh"
}

# üß† –ö–µ—à–∏—Ä–∞–º–µ –≤–µ—á–µ –∑–∞—Ä–µ–¥–µ–Ω–∏ –º–æ–¥–µ–ª–∏
loaded_models = {}

def load_model(model_name):
    if model_name not in loaded_models:
        try:
            tokenizer = MarianTokenizer.from_pretrained(model_name)
            model = MarianMTModel.from_pretrained(model_name)
            loaded_models[model_name] = (tokenizer, model)
        except Exception as e:
            raise RuntimeError(f"‚ö†Ô∏è –ù–µ—É—Å–ø–µ—à–Ω–æ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª–∞: {model_name}\n–ì—Ä–µ—à–∫–∞: {str(e)}")
    return loaded_models[model_name]

# üó£ –§—É–Ω–∫—Ü–∏—è –∑–∞ –ø—Ä–µ–≤–æ–¥
def translate(text, src_name, tgt_name):
    try:
        text = text.strip()
        if not text:
            return "‚ùó –ú–æ–ª—è, –≤—ä–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –∑–∞ –ø—Ä–µ–≤–æ–¥."

        src_lang = lang_options.get(src_name)
        tgt_lang = lang_options.get(tgt_name)

        if not src_lang or not tgt_lang:
            return "‚ùó –ò–∑–±—Ä–∞–Ω–∏—Ç–µ –µ–∑–∏—Ü–∏ –Ω–µ —Å–∞ –≤–∞–ª–∏–¥–Ω–∏."

        if (src_lang, tgt_lang) not in language_pairs:
            return f"‚ùå –¢–∞–∑–∏ –µ–∑–∏–∫–æ–≤–∞ –¥–≤–æ–π–∫–∞ ({src_lang} ‚Üí {tgt_lang}) –Ω–µ —Å–µ –ø–æ–¥–¥—ä—Ä–∂–∞."

        model_name = language_pairs[(src_lang, tgt_lang)]
        tokenizer, model = load_model(model_name)

        tokens = tokenizer(text, return_tensors="pt", padding=True)
        translation = model.generate(**tokens)
        translated_text = tokenizer.decode(translation[0], skip_special_tokens=True)

        return translated_text

    except Exception as e:
        return f"üí• –í—ä–∑–Ω–∏–∫–Ω–∞ –≥—Ä–µ—à–∫–∞ –ø—Ä–∏ –ø—Ä–µ–≤–æ–¥:\n{str(e)}"

# üåê –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å Gradio
gr.Interface(
    fn=translate,
    inputs=[
        gr.Textbox(label="üìù –í—ä–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –∑–∞ –ø—Ä–µ–≤–æ–¥"),
        gr.Dropdown(choices=list(lang_options.keys()), label="–ò–∑—Ö–æ–¥–µ–Ω –µ–∑–∏–∫"),
        gr.Dropdown(choices=list(lang_options.keys()), label="–¶–µ–ª–µ–≤–∏ –µ–∑–∏–∫")
    ],
    outputs=gr.Textbox(label="‚úÖ –ü—Ä–µ–≤–µ–¥–µ–Ω —Ç–µ–∫—Å—Ç"),
    title="üåç AI –ü—Ä–µ–≤–æ–¥–∞—á",
    description="–ú–Ω–æ–≥–æ–µ–∑–∏—á–µ–Ω –ø—Ä–µ–≤–æ–¥ —Å –∏–∑–∫—É—Å—Ç–≤–µ–Ω –∏–Ω—Ç–µ–ª–µ–∫—Ç –º–µ–∂–¥—É –±—ä–ª–≥–∞—Ä—Å–∫–∏, –∞–Ω–≥–ª–∏–π—Å–∫–∏, —Ä—É—Å–∫–∏ –∏ –∫–∏—Ç–∞–π—Å–∫–∏.",
    theme="default"
).launch()